{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_path = 'data/small_vocab_en'\n",
    "target_path = 'data/small_vocab_fr'\n",
    "source_text = load_data(source_path)\n",
    "target_text = load_data(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Brief Stats\n",
      "* number of unique words in English sample sentences: 227        [this is roughly measured/without any preprocessing]\n",
      "\n",
      "* English sentences\n",
      "\t- number of sentences: 137861\n",
      "\t- avg. number of words in a sentence: 13.225277634719028\n",
      "* French sentences\n",
      "\t- number of sentences: 137861 [data integrity check / should have the same number]\n",
      "\t- avg. number of words in a sentence: 14.226612312401622\n",
      "\n",
      "* Sample sentences range from 0 to 5\n",
      "[1-th] sentence\n",
      "\tEN: new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "\tFR: new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "\n",
      "[2-th] sentence\n",
      "\tEN: the united states is usually chilly during july , and it is usually freezing in november .\n",
      "\tFR: les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "\n",
      "[3-th] sentence\n",
      "\tEN: california is usually quiet during march , and it is usually hot in june .\n",
      "\tFR: california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "\n",
      "[4-th] sentence\n",
      "\tEN: the united states is sometimes mild during june , and it is cold in september .\n",
      "\tFR: les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "\n",
      "[5-th] sentence\n",
      "\tEN: your least liked fruit is the grape , but my least liked is the apple .\n",
      "\tFR: votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "print('Dataset Brief Stats')\n",
    "print('* number of unique words in English sample sentences: {}\\\n",
    "        [this is roughly measured/without any preprocessing]'.format(len(Counter(source_text.split()))))\n",
    "print()\n",
    "\n",
    "english_sentences = source_text.split('\\n')\n",
    "print('* English sentences')\n",
    "print('\\t- number of sentences: {}'.format(len(english_sentences)))\n",
    "print('\\t- avg. number of words in a sentence: {}'.format(np.average([len(sentence.split()) for sentence in english_sentences])))\n",
    "\n",
    "french_sentences = target_text.split('\\n')\n",
    "print('* French sentences')\n",
    "print('\\t- number of sentences: {} [data integrity check / should have the same number]'.format(len(french_sentences)))\n",
    "print('\\t- avg. number of words in a sentence: {}'.format(np.average([len(sentence.split()) for sentence in french_sentences])))\n",
    "print()\n",
    "\n",
    "sample_sentence_range = (0, 5)\n",
    "side_by_side_sentences = list(zip(english_sentences, french_sentences))[sample_sentence_range[0]:sample_sentence_range[1]]\n",
    "print('* Sample sentences range from {} to {}'.format(sample_sentence_range[0], sample_sentence_range[1]))\n",
    "\n",
    "for index, sentence in enumerate(side_by_side_sentences):\n",
    "    en_sent, fr_sent = sentence\n",
    "    print('[{}-th] sentence'.format(index+1))\n",
    "    print('\\tEN: {}'.format(en_sent))\n",
    "    print('\\tFR: {}'.format(fr_sent))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3}\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    vocab = set(text.split())\n",
    "    \n",
    "    vocab_to_int = copy.copy(CODES)\n",
    "    for v_i, v in enumerate(vocab, len(CODES)):\n",
    "        vocab_to_int[v] = v_i\n",
    "        \n",
    "    int_to_vocab = {v_i:v for v, v_i in vocab_to_int.items()}\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "        1st, 2nd args: raw string text to be converted\n",
    "        3rd, 4th args: lookup tables for 1st and 2nd args respectively\n",
    "    \n",
    "        return: A tuple of lists (source_id_text, target_id_text) converted\n",
    "    \"\"\"\n",
    "    # empty list of converted sentences\n",
    "    source_text_id = []\n",
    "    target_text_id = []\n",
    "    \n",
    "    # make a list of sentences (extraction)\n",
    "    source_sentences = source_text.split(\"\\n\")\n",
    "    target_sentences = target_text.split(\"\\n\")\n",
    "    \n",
    "    max_source_sentence_length = max([len(sentence.split(\" \")) for sentence in source_sentences])\n",
    "    max_target_sentence_length = max([len(sentence.split(\" \")) for sentence in target_sentences])\n",
    "    \n",
    "    # iterating through each sentences (# of sentences in source&target is the same)\n",
    "    for i in range(len(source_sentences)):\n",
    "        # extract sentences one by one\n",
    "        source_sentence = source_sentences[i]\n",
    "        target_sentence = target_sentences[i]\n",
    "        \n",
    "        # make a list of tokens/words (extraction) from the chosen sentence\n",
    "        source_tokens = source_sentence.split(\" \")\n",
    "        target_tokens = target_sentence.split(\" \")\n",
    "        \n",
    "        # empty list of converted words to index in the chosen sentence\n",
    "        source_token_id = []\n",
    "        target_token_id = []\n",
    "        \n",
    "        for index, token in enumerate(source_tokens):\n",
    "            if (token != \"\"):\n",
    "                source_token_id.append(source_vocab_to_int[token])\n",
    "        \n",
    "        for index, token in enumerate(target_tokens):\n",
    "            if (token != \"\"):\n",
    "                target_token_id.append(target_vocab_to_int[token])\n",
    "                \n",
    "        # put <EOS> token at the end of the chosen target sentence\n",
    "        # this token suggests when to stop creating a sequence\n",
    "        target_token_id.append(target_vocab_to_int['<EOS>'])\n",
    "            \n",
    "        # add each converted sentences in the final list\n",
    "        source_text_id.append(source_token_id)\n",
    "        target_text_id.append(target_token_id)\n",
    "    \n",
    "    return source_text_id, target_text_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_and_save_data(source_path, target_path, text_to_ids):\n",
    "    # Preprocess\n",
    "    \n",
    "    # load original data (English, French)\n",
    "    source_text = load_data(source_path)\n",
    "    target_text = load_data(target_path)\n",
    "\n",
    "    # to the lower case\n",
    "    source_text = source_text.lower()\n",
    "    target_text = target_text.lower()\n",
    "\n",
    "    # create lookup tables for English and French data\n",
    "    source_vocab_to_int, source_int_to_vocab = create_lookup_tables(source_text)\n",
    "    target_vocab_to_int, target_int_to_vocab = create_lookup_tables(target_text)\n",
    "\n",
    "    # create list of sentences whose words are represented in index\n",
    "    source_text, target_text = text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int)\n",
    "\n",
    "    # Save data for later use\n",
    "    pickle.dump((\n",
    "        (source_text, target_text),\n",
    "        (source_vocab_to_int, target_vocab_to_int),\n",
    "        (source_int_to_vocab, target_int_to_vocab)), open('jzpreprocess.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess_and_save_data(source_path, target_path, text_to_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_preprocess():\n",
    "    with open('jzpreprocess.p', mode='rb') as in_file:\n",
    "        return pickle.load(in_file)\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Version of TensorFlow and Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiozhan/anaconda3/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/jiozhan/anaconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiozhan/anaconda3/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:11: UserWarning: No GPU found. Please use a GPU to train your neural network.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.1'), 'Please use TensorFlow version 1.1 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "\n",
    "archetecture steps:\n",
    "    1. input parameters to the encoder model: enc_dec_model_inputs\n",
    "    2. input parameters to the decoder model: enc_dec_model_inputs, process_decoder_input, decoding_layer\n",
    "    3. encoder model: encoding_layer\n",
    "    4. decoder model for training: decoding_layer_train\n",
    "    5. decoder model for inference: decoding_layer_infer\n",
    "    6. decoding model (4. 5. together): decoding_layer\n",
    "    7. connect encoder and decoder: seq2seq_model\n",
    "    8. loss, optimizer, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 1. Input parameters\n",
    "\n",
    "# model inputs\n",
    "def enc_dec_model_inputs():\n",
    "    inputs_ = tf.placeholder(tf.int32, [None, None], name = 'input')\n",
    "    targets_ = tf.placeholder(tf.int32, [None, None], name = 'targets')\n",
    "    \n",
    "    target_sequence_length = tf.placeholder(tf.int32, [None], name='target_sequence_length')\n",
    "    max_target_len = tf.reduce_max(target_sequence_length)\n",
    "    \n",
    "    return inputs_, targets_, target_sequence_length, max_target_len\n",
    "\n",
    "# hyperparameters inputs: learning rate, dropout rate\n",
    "def hyperparam_inputs():\n",
    "    lr_rate = tf.placeholder(tf.float32, name='lr_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return lr_rate, keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process decoder input (add <GO> token)\n",
    "def process_decoder_input(target_data, target_vocab_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocess target data for encoding\n",
    "    :return: Preprocessed target data\n",
    "    \"\"\"\n",
    "    go_id = target_vocab_to_int['<GO>']\n",
    "    \n",
    "    after_slice = tf.strided_slice(target_data, [0,0], [batch_size, -1], [1,1])\n",
    "    after_concat = tf.concat( [tf.fill([batch_size, 1], go_id), after_slice], 1)\n",
    "    \n",
    "    return after_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 3. Encoding\n",
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob,\n",
    "                  source_vocab_size, encoding_embedding_size):\n",
    "    \"\"\"\n",
    "    return: tuple (RNN output, RNN state)\n",
    "    \"\"\"\n",
    "    # embedding layer\n",
    "    embed = tf.contrib.layers.embed_sequence(rnn_inputs,\n",
    "                                             vocab_size=source_vocab_size,\n",
    "                                             embed_dim=encoding_embedding_size)\n",
    "    \n",
    "    # rnn cell\n",
    "    #lstm_cell = tf.contrib.rnn.LSTMCell(rnn_size)\n",
    "    #cell = tf.contrib.rnn.DropoutWrapper(lstm_cell, keep_prob)\n",
    "    #stacked_cells = tf.contrib.rnn.MultiRNNCell([cell for _ in range(num_layers)])\n",
    "    LSTM_CELL = tf.contrib.rnn.LSTMCell\n",
    "    DW = tf.contrib.rnn.DropoutWrapper\n",
    "    stacked_cells = tf.contrib.rnn.MultiRNNCell(\n",
    "        [DW(LSTM_CELL(rnn_size), keep_prob) for _ in range(num_layers)])\n",
    "    \n",
    "    # computation graph\n",
    "    outputs, state = tf.nn.dynamic_rnn(stacked_cells,\n",
    "                                       embed,\n",
    "                                       dtype=tf.float32)\n",
    "    return outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 4. Decoding components (training, inference)\n",
    "\n",
    "# decoding - training\n",
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, \n",
    "                        target_sequence_length, max_target_sequence_length,\n",
    "                        output_layer, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a training process in decoding layer\n",
    "    return: BasicDecoderOutput containing training logits and sample_id\n",
    "    \"\"\"\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell, \n",
    "                                             output_keep_prob = keep_prob)\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input,\n",
    "                                              target_sequence_length)\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                              helper,\n",
    "                                              encoder_state,\n",
    "                                              output_layer)\n",
    "    # unrolling the decoder layer\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder,\n",
    "                                                      impute_finished=True,\n",
    "                                                      maximum_iterations=max_target_sequence_length)\n",
    "    return outputs\n",
    "\n",
    "# decoding - inference\n",
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embed_input, start_of_sequence_id,\n",
    "                         end_of_sequence_id, max_target_sequence_length, \n",
    "                         vocab_size, output_layer, batch_size, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a inference process in decoding layer\n",
    "    return: BasicDecoderOutput containing inference logits and sample_id\n",
    "    \"\"\"\n",
    "    dec_cell = tf.contrib.rnn.DropoutWrapper(dec_cell,\n",
    "                                             output_keep_prob = keep_prob)\n",
    "    \n",
    "    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embed_input,\n",
    "                                                      tf.fill([batch_size], start_of_sequence_id),\n",
    "                                                      end_of_sequence_id)\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                             helper,\n",
    "                                             encoder_state,\n",
    "                                             output_layer)\n",
    "    # unrolling of the decoder\n",
    "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder,\n",
    "                                                      impute_finished=True,\n",
    "                                                      maximum_iterations=max_target_sequence_length)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 5. Decoding layer\n",
    "def decoding_layer(dec_input, encoder_state,\n",
    "                  target_sequence_length, max_target_sequence_length,\n",
    "                  rnn_size, num_layers, \n",
    "                  target_vocab_to_int, target_vocab_size,\n",
    "                  batch_size, keep_prob, decoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create decoding layer\n",
    "    return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    \n",
    "    # embedding\n",
    "    target_vocab_size = len(target_vocab_to_int)\n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "    \n",
    "    # dec cell\n",
    "    LSTM_CELL = tf.contrib.rnn.LSTMCell\n",
    "    cells = tf.contrib.rnn.MultiRNNCell([LSTM_CELL(rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    #cells = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        output_layer = tf.layers.Dense(target_vocab_size)\n",
    "        train_output = decoding_layer_train(encoder_state,\n",
    "                                            cells,\n",
    "                                            dec_embed_input,\n",
    "                                            target_sequence_length,\n",
    "                                            max_target_sequence_length,\n",
    "                                            output_layer,\n",
    "                                            keep_prob)\n",
    "        \n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        infer_output = decoding_layer_infer(encoder_state,\n",
    "                                            cells,\n",
    "                                            dec_embeddings,\n",
    "                                            target_vocab_to_int['<GO>'], \n",
    "                                            target_vocab_to_int['<EOS>'], \n",
    "                                            max_target_sequence_length,\n",
    "                                            target_vocab_size,\n",
    "                                            output_layer,\n",
    "                                            batch_size,\n",
    "                                            keep_prob)\n",
    "        \n",
    "    return (train_output, infer_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Note: different cell object for stacked layers ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [`tf.contrib.seq2seq.TrainingHelper`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper)\n",
    "  - TrainingHelper is where we pass the embeded input. As the name indicates, this is only a helper instance. This instance should be delivered to the BasicDecoder, which is the actual process of building the decoder model.\n",
    "- [`tf.contrib.seq2seq.BasicDecoder`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder)\n",
    "  - BasicDecoder builds the decoder model. It means it connects the RNN layer(s) on the decoder side and the input prepared by TrainingHelper.\n",
    "- [`tf.contrib.seq2seq.dynamic_decode`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode)\n",
    "  - dynamic_decode unrolls the decoder model so that actual prediction can be retrieved by BasicDecoder for each time steps.\n",
    "  \n",
    "- [`tf.contrib.seq2seq.GreedyEmbeddingHelper`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper)\n",
    "  - GreedyEmbeddingHelper dynamically takes the output of the current step and give it to the next time step's input. In order to embed the each input result dynamically, embedding parameter(just bunch of weight values) should be provided. Along with it, GreedyEmbeddingHelper asks to give the `start_of_sequence_id` for the same amount as the batch size and `end_of_sequence_id`.\n",
    "- [`tf.contrib.seq2seq.BasicDecoder`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder)\n",
    "  - same as described in the training process section\n",
    "- [`tf.contrib.seq2seq.dynamic_decode`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode)\n",
    "  - same as described in the training process section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 7. Seq2Seq model\n",
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n",
    "                  target_sequence_length, max_target_sentence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size,\n",
    "                  rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Build the Sequence-to-Sequence model\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    enc_outputs, enc_states = encoding_layer(input_data,\n",
    "                                             rnn_size,\n",
    "                                             num_layers,\n",
    "                                             keep_prob,\n",
    "                                             source_vocab_size,\n",
    "                                             enc_embedding_size)\n",
    "    dec_input = process_decoder_input(target_data,\n",
    "                                      target_vocab_to_int,\n",
    "                                      batch_size)\n",
    "    train_output, infer_output = decoding_layer(dec_input,\n",
    "                                                enc_states,\n",
    "                                                target_sequence_length,\n",
    "                                                max_target_sentence_length,\n",
    "                                                rnn_size,\n",
    "                                                num_layers,\n",
    "                                                target_vocab_to_int,\n",
    "                                                target_vocab_size,\n",
    "                                                batch_size,\n",
    "                                                keep_prob,\n",
    "                                                dec_embedding_size)\n",
    "    return train_output, infer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### hyperparameters\n",
    "\n",
    "display_step = 300\n",
    "\n",
    "epochs = 13\n",
    "batch_size = 32\n",
    "\n",
    "rnn_size = 128\n",
    "num_layers = 2\n",
    "\n",
    "encoding_embedding_size = 200\n",
    "decoding_embedding_size = 200\n",
    "\n",
    "learning_rate = 0.001\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### 8. Build up computation graph\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    # tensors for inputs\n",
    "    input_data, targets, target_sequence_length, max_target_sequence_length = enc_dec_model_inputs()\n",
    "    lr, keep_prob = hyperparam_inputs()\n",
    "    \n",
    "    # seq2seq model in graph\n",
    "    train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                   targets,\n",
    "                                                   keep_prob,\n",
    "                                                   batch_size,\n",
    "                                                   target_sequence_length,\n",
    "                                                   max_target_sequence_length,\n",
    "                                                   len(source_vocab_to_int),\n",
    "                                                   len(target_vocab_to_int),\n",
    "                                                   encoding_embedding_size,\n",
    "                                                   decoding_embedding_size,\n",
    "                                                   rnn_size,\n",
    "                                                   num_layers,\n",
    "                                                   target_vocab_to_int)\n",
    "    \n",
    "    training_logits = tf.identity(train_logits.rnn_output, name='logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "    \n",
    "    masks = tf.sequence_mask(target_sequence_length, \n",
    "                             max_target_sequence_length, \n",
    "                             dtype=tf.float32, name='mask')\n",
    "    \n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "                training_logits,\n",
    "                targets,\n",
    "                masks)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "        \n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1, 1), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = 'checkpoints/dev'\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = load_preprocess()\n",
    "max_target_sentence_length = max([len(sentence) for sentence in source_int_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get batches and pad senquences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n",
    "\n",
    "\n",
    "def get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "\n",
    "        # Slice the right amount for the batch\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "\n",
    "        # Pad\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "\n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "\n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "\n",
    "        yield pad_sources_batch, pad_targets_batch, pad_source_lengths, pad_targets_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch  300/4308 - Train Accuracy: 0.3733, Validation Accuracy: 0.3799, Loss: 1.8547\n",
      "Epoch   0 Batch  600/4308 - Train Accuracy: 0.4859, Validation Accuracy: 0.4539, Loss: 1.0613\n",
      "Epoch   0 Batch  900/4308 - Train Accuracy: 0.4178, Validation Accuracy: 0.4572, Loss: 0.9386\n",
      "Epoch   0 Batch 1200/4308 - Train Accuracy: 0.5563, Validation Accuracy: 0.5033, Loss: 0.8365\n",
      "Epoch   0 Batch 1500/4308 - Train Accuracy: 0.5188, Validation Accuracy: 0.5362, Loss: 0.7322\n",
      "Epoch   0 Batch 1800/4308 - Train Accuracy: 0.5938, Validation Accuracy: 0.5839, Loss: 0.6344\n",
      "Epoch   0 Batch 2100/4308 - Train Accuracy: 0.6184, Validation Accuracy: 0.5625, Loss: 0.6022\n",
      "Epoch   0 Batch 2400/4308 - Train Accuracy: 0.7125, Validation Accuracy: 0.5855, Loss: 0.5325\n",
      "Epoch   0 Batch 2700/4308 - Train Accuracy: 0.6594, Validation Accuracy: 0.6036, Loss: 0.5229\n",
      "Epoch   0 Batch 3000/4308 - Train Accuracy: 0.6219, Validation Accuracy: 0.6316, Loss: 0.5067\n",
      "Epoch   0 Batch 3300/4308 - Train Accuracy: 0.6891, Validation Accuracy: 0.6003, Loss: 0.4598\n",
      "Epoch   0 Batch 3600/4308 - Train Accuracy: 0.7089, Validation Accuracy: 0.6398, Loss: 0.4369\n",
      "Epoch   0 Batch 3900/4308 - Train Accuracy: 0.6875, Validation Accuracy: 0.6283, Loss: 0.3535\n",
      "Epoch   0 Batch 4200/4308 - Train Accuracy: 0.7578, Validation Accuracy: 0.6283, Loss: 0.3181\n",
      "Epoch   1 Batch  300/4308 - Train Accuracy: 0.8090, Validation Accuracy: 0.7730, Loss: 0.3212\n",
      "Epoch   1 Batch  600/4308 - Train Accuracy: 0.8078, Validation Accuracy: 0.7615, Loss: 0.2392\n",
      "Epoch   1 Batch  900/4308 - Train Accuracy: 0.8306, Validation Accuracy: 0.8372, Loss: 0.2278\n",
      "Epoch   1 Batch 1200/4308 - Train Accuracy: 0.7625, Validation Accuracy: 0.8174, Loss: 0.3271\n",
      "Epoch   1 Batch 1500/4308 - Train Accuracy: 0.8406, Validation Accuracy: 0.7862, Loss: 0.2419\n",
      "Epoch   1 Batch 1800/4308 - Train Accuracy: 0.8750, Validation Accuracy: 0.7895, Loss: 0.1755\n",
      "Epoch   1 Batch 2100/4308 - Train Accuracy: 0.8553, Validation Accuracy: 0.7961, Loss: 0.1938\n",
      "Epoch   1 Batch 2400/4308 - Train Accuracy: 0.9328, Validation Accuracy: 0.8832, Loss: 0.1329\n",
      "Epoch   1 Batch 2700/4308 - Train Accuracy: 0.9078, Validation Accuracy: 0.8997, Loss: 0.1700\n",
      "Epoch   1 Batch 3000/4308 - Train Accuracy: 0.8281, Validation Accuracy: 0.8914, Loss: 0.1679\n",
      "Epoch   1 Batch 3300/4308 - Train Accuracy: 0.9260, Validation Accuracy: 0.8536, Loss: 0.1385\n",
      "Epoch   1 Batch 3600/4308 - Train Accuracy: 0.8832, Validation Accuracy: 0.8799, Loss: 0.1617\n",
      "Epoch   1 Batch 3900/4308 - Train Accuracy: 0.9243, Validation Accuracy: 0.8816, Loss: 0.1289\n",
      "Epoch   1 Batch 4200/4308 - Train Accuracy: 0.8969, Validation Accuracy: 0.9013, Loss: 0.1105\n",
      "Epoch   2 Batch  300/4308 - Train Accuracy: 0.8681, Validation Accuracy: 0.8832, Loss: 0.1251\n",
      "Epoch   2 Batch  600/4308 - Train Accuracy: 0.9062, Validation Accuracy: 0.9326, Loss: 0.0895\n",
      "Epoch   2 Batch  900/4308 - Train Accuracy: 0.9095, Validation Accuracy: 0.9326, Loss: 0.1070\n",
      "Epoch   2 Batch 1200/4308 - Train Accuracy: 0.8781, Validation Accuracy: 0.9079, Loss: 0.1623\n",
      "Epoch   2 Batch 1500/4308 - Train Accuracy: 0.8641, Validation Accuracy: 0.8931, Loss: 0.1059\n",
      "Epoch   2 Batch 1800/4308 - Train Accuracy: 0.9203, Validation Accuracy: 0.9441, Loss: 0.0799\n",
      "Epoch   2 Batch 2100/4308 - Train Accuracy: 0.9013, Validation Accuracy: 0.9211, Loss: 0.0692\n",
      "Epoch   2 Batch 2400/4308 - Train Accuracy: 0.9781, Validation Accuracy: 0.9638, Loss: 0.0706\n",
      "Epoch   2 Batch 2700/4308 - Train Accuracy: 0.9625, Validation Accuracy: 0.9424, Loss: 0.0834\n",
      "Epoch   2 Batch 3000/4308 - Train Accuracy: 0.9234, Validation Accuracy: 0.9572, Loss: 0.0849\n",
      "Epoch   2 Batch 3300/4308 - Train Accuracy: 0.9079, Validation Accuracy: 0.9474, Loss: 0.0541\n",
      "Epoch   2 Batch 3600/4308 - Train Accuracy: 0.9441, Validation Accuracy: 0.9474, Loss: 0.0919\n",
      "Epoch   2 Batch 3900/4308 - Train Accuracy: 0.9441, Validation Accuracy: 0.9507, Loss: 0.0663\n",
      "Epoch   2 Batch 4200/4308 - Train Accuracy: 0.9641, Validation Accuracy: 0.9391, Loss: 0.0405\n",
      "Epoch   3 Batch  300/4308 - Train Accuracy: 0.9340, Validation Accuracy: 0.9770, Loss: 0.0760\n",
      "Epoch   3 Batch  600/4308 - Train Accuracy: 0.9047, Validation Accuracy: 0.9671, Loss: 0.0477\n",
      "Epoch   3 Batch  900/4308 - Train Accuracy: 0.9079, Validation Accuracy: 0.9441, Loss: 0.0657\n",
      "Epoch   3 Batch 1200/4308 - Train Accuracy: 0.9156, Validation Accuracy: 0.9753, Loss: 0.1370\n",
      "Epoch   3 Batch 1500/4308 - Train Accuracy: 0.8844, Validation Accuracy: 0.9293, Loss: 0.0651\n",
      "Epoch   3 Batch 1800/4308 - Train Accuracy: 0.9313, Validation Accuracy: 0.9276, Loss: 0.0488\n",
      "Epoch   3 Batch 2100/4308 - Train Accuracy: 0.9622, Validation Accuracy: 0.9556, Loss: 0.0467\n",
      "Epoch   3 Batch 2400/4308 - Train Accuracy: 0.9859, Validation Accuracy: 0.9490, Loss: 0.0400\n",
      "Epoch   3 Batch 2700/4308 - Train Accuracy: 0.9688, Validation Accuracy: 0.9556, Loss: 0.0647\n",
      "Epoch   3 Batch 3000/4308 - Train Accuracy: 0.9156, Validation Accuracy: 0.9441, Loss: 0.0728\n",
      "Epoch   3 Batch 3300/4308 - Train Accuracy: 0.9293, Validation Accuracy: 0.9638, Loss: 0.0533\n",
      "Epoch   3 Batch 3600/4308 - Train Accuracy: 0.9539, Validation Accuracy: 0.9556, Loss: 0.0663\n",
      "Epoch   3 Batch 3900/4308 - Train Accuracy: 0.9441, Validation Accuracy: 0.9688, Loss: 0.0425\n",
      "Epoch   3 Batch 4200/4308 - Train Accuracy: 0.9313, Validation Accuracy: 0.9934, Loss: 0.0392\n",
      "Epoch   4 Batch  300/4308 - Train Accuracy: 0.9201, Validation Accuracy: 0.9572, Loss: 0.0777\n",
      "Epoch   4 Batch  600/4308 - Train Accuracy: 0.9266, Validation Accuracy: 0.9539, Loss: 0.0371\n",
      "Epoch   4 Batch  900/4308 - Train Accuracy: 0.8865, Validation Accuracy: 0.9770, Loss: 0.0357\n",
      "Epoch   4 Batch 1200/4308 - Train Accuracy: 0.9594, Validation Accuracy: 0.9753, Loss: 0.0823\n",
      "Epoch   4 Batch 1500/4308 - Train Accuracy: 0.9109, Validation Accuracy: 0.9967, Loss: 0.0840\n",
      "Epoch   4 Batch 1800/4308 - Train Accuracy: 0.9328, Validation Accuracy: 0.9556, Loss: 0.0464\n",
      "Epoch   4 Batch 2100/4308 - Train Accuracy: 0.9786, Validation Accuracy: 0.9539, Loss: 0.0335\n",
      "Epoch   4 Batch 2400/4308 - Train Accuracy: 0.9844, Validation Accuracy: 0.9770, Loss: 0.0192\n",
      "Epoch   4 Batch 2700/4308 - Train Accuracy: 0.9750, Validation Accuracy: 0.9556, Loss: 0.0547\n",
      "Epoch   4 Batch 3000/4308 - Train Accuracy: 0.9703, Validation Accuracy: 0.9737, Loss: 0.0596\n",
      "Epoch   4 Batch 3300/4308 - Train Accuracy: 0.9737, Validation Accuracy: 0.9753, Loss: 0.0330\n",
      "Epoch   4 Batch 3600/4308 - Train Accuracy: 0.9589, Validation Accuracy: 0.9474, Loss: 0.0460\n",
      "Epoch   4 Batch 3900/4308 - Train Accuracy: 0.9441, Validation Accuracy: 0.9770, Loss: 0.0263\n",
      "Epoch   4 Batch 4200/4308 - Train Accuracy: 0.9328, Validation Accuracy: 0.9770, Loss: 0.0453\n",
      "Epoch   5 Batch  300/4308 - Train Accuracy: 0.9375, Validation Accuracy: 0.9753, Loss: 0.0387\n",
      "Epoch   5 Batch  600/4308 - Train Accuracy: 0.9297, Validation Accuracy: 0.9490, Loss: 0.0203\n",
      "Epoch   5 Batch  900/4308 - Train Accuracy: 0.9408, Validation Accuracy: 0.9539, Loss: 0.0426\n",
      "Epoch   5 Batch 1200/4308 - Train Accuracy: 0.9375, Validation Accuracy: 0.9984, Loss: 0.0697\n",
      "Epoch   5 Batch 1500/4308 - Train Accuracy: 0.9047, Validation Accuracy: 0.9490, Loss: 0.0735\n",
      "Epoch   5 Batch 1800/4308 - Train Accuracy: 0.9344, Validation Accuracy: 0.9984, Loss: 0.0315\n",
      "Epoch   5 Batch 2100/4308 - Train Accuracy: 0.9885, Validation Accuracy: 0.9753, Loss: 0.0246\n",
      "Epoch   5 Batch 2400/4308 - Train Accuracy: 0.9859, Validation Accuracy: 0.9770, Loss: 0.0247\n",
      "Epoch   5 Batch 2700/4308 - Train Accuracy: 0.9406, Validation Accuracy: 0.9770, Loss: 0.0316\n",
      "Epoch   5 Batch 3000/4308 - Train Accuracy: 0.9313, Validation Accuracy: 0.9984, Loss: 0.0443\n",
      "Epoch   5 Batch 3300/4308 - Train Accuracy: 0.9770, Validation Accuracy: 0.9786, Loss: 0.0297\n",
      "Epoch   5 Batch 3600/4308 - Train Accuracy: 0.9803, Validation Accuracy: 0.9984, Loss: 0.0429\n",
      "Epoch   5 Batch 3900/4308 - Train Accuracy: 0.9704, Validation Accuracy: 0.9984, Loss: 0.0173\n",
      "Epoch   5 Batch 4200/4308 - Train Accuracy: 0.9328, Validation Accuracy: 0.9786, Loss: 0.0247\n",
      "Epoch   6 Batch  300/4308 - Train Accuracy: 0.9132, Validation Accuracy: 0.9786, Loss: 0.0554\n",
      "Epoch   6 Batch  600/4308 - Train Accuracy: 0.9797, Validation Accuracy: 0.9967, Loss: 0.0189\n",
      "Epoch   6 Batch  900/4308 - Train Accuracy: 0.9391, Validation Accuracy: 0.9770, Loss: 0.0480\n",
      "Epoch   6 Batch 1200/4308 - Train Accuracy: 0.9609, Validation Accuracy: 0.9704, Loss: 0.0832\n",
      "Epoch   6 Batch 1500/4308 - Train Accuracy: 0.9219, Validation Accuracy: 0.9704, Loss: 0.0481\n",
      "Epoch   6 Batch 1800/4308 - Train Accuracy: 0.9344, Validation Accuracy: 0.9539, Loss: 0.0235\n",
      "Epoch   6 Batch 2100/4308 - Train Accuracy: 0.9803, Validation Accuracy: 0.9967, Loss: 0.0314\n",
      "Epoch   6 Batch 2400/4308 - Train Accuracy: 1.0000, Validation Accuracy: 0.9753, Loss: 0.0140\n",
      "Epoch   6 Batch 2700/4308 - Train Accuracy: 0.9812, Validation Accuracy: 0.9293, Loss: 0.0361\n",
      "Epoch   6 Batch 3000/4308 - Train Accuracy: 0.9750, Validation Accuracy: 0.9984, Loss: 0.0236\n",
      "Epoch   6 Batch 3300/4308 - Train Accuracy: 0.9539, Validation Accuracy: 0.9786, Loss: 0.0259\n",
      "Epoch   6 Batch 3600/4308 - Train Accuracy: 0.9803, Validation Accuracy: 0.9572, Loss: 0.0266\n",
      "Epoch   6 Batch 3900/4308 - Train Accuracy: 0.9704, Validation Accuracy: 0.9984, Loss: 0.0233\n",
      "Epoch   6 Batch 4200/4308 - Train Accuracy: 0.9094, Validation Accuracy: 0.9786, Loss: 0.0343\n",
      "Epoch   7 Batch  300/4308 - Train Accuracy: 0.9184, Validation Accuracy: 0.9786, Loss: 0.0515\n",
      "Epoch   7 Batch  600/4308 - Train Accuracy: 0.9281, Validation Accuracy: 0.9770, Loss: 0.0205\n",
      "Epoch   7 Batch  900/4308 - Train Accuracy: 0.8898, Validation Accuracy: 0.9474, Loss: 0.0242\n",
      "Epoch   7 Batch 1200/4308 - Train Accuracy: 0.9656, Validation Accuracy: 0.9704, Loss: 0.0645\n",
      "Epoch   7 Batch 1500/4308 - Train Accuracy: 0.9531, Validation Accuracy: 0.9786, Loss: 0.0478\n",
      "Epoch   7 Batch 1800/4308 - Train Accuracy: 0.9547, Validation Accuracy: 0.9984, Loss: 0.0225\n",
      "Epoch   7 Batch 2100/4308 - Train Accuracy: 1.0000, Validation Accuracy: 0.9786, Loss: 0.0305\n",
      "Epoch   7 Batch 2400/4308 - Train Accuracy: 0.9859, Validation Accuracy: 0.9984, Loss: 0.0139\n",
      "Epoch   7 Batch 2700/4308 - Train Accuracy: 0.9547, Validation Accuracy: 0.9984, Loss: 0.0295\n",
      "Epoch   7 Batch 3000/4308 - Train Accuracy: 0.9875, Validation Accuracy: 0.9984, Loss: 0.0277\n",
      "Epoch   7 Batch 3300/4308 - Train Accuracy: 0.9737, Validation Accuracy: 0.9984, Loss: 0.0255\n",
      "Epoch   7 Batch 3600/4308 - Train Accuracy: 0.9918, Validation Accuracy: 0.9753, Loss: 0.0348\n",
      "Epoch   7 Batch 3900/4308 - Train Accuracy: 0.9704, Validation Accuracy: 0.9984, Loss: 0.0193\n",
      "Epoch   7 Batch 4200/4308 - Train Accuracy: 0.9547, Validation Accuracy: 0.9786, Loss: 0.0288\n",
      "Epoch   8 Batch  300/4308 - Train Accuracy: 0.9306, Validation Accuracy: 0.9984, Loss: 0.0376\n",
      "Epoch   8 Batch  600/4308 - Train Accuracy: 0.9812, Validation Accuracy: 0.9984, Loss: 0.0112\n",
      "Epoch   8 Batch  900/4308 - Train Accuracy: 0.9408, Validation Accuracy: 0.9967, Loss: 0.0254\n",
      "Epoch   8 Batch 1200/4308 - Train Accuracy: 0.9797, Validation Accuracy: 0.9704, Loss: 0.0379\n",
      "Epoch   8 Batch 1500/4308 - Train Accuracy: 0.9328, Validation Accuracy: 0.9984, Loss: 0.0398\n",
      "Epoch   8 Batch 1800/4308 - Train Accuracy: 0.9563, Validation Accuracy: 0.9984, Loss: 0.0210\n",
      "Epoch   8 Batch 2100/4308 - Train Accuracy: 0.9819, Validation Accuracy: 0.9984, Loss: 0.0137\n",
      "Epoch   8 Batch 2400/4308 - Train Accuracy: 0.9984, Validation Accuracy: 0.9803, Loss: 0.0190\n",
      "Epoch   8 Batch 2700/4308 - Train Accuracy: 0.9891, Validation Accuracy: 0.9770, Loss: 0.0339\n",
      "Epoch   8 Batch 3000/4308 - Train Accuracy: 0.9875, Validation Accuracy: 0.9984, Loss: 0.0263\n",
      "Epoch   8 Batch 3300/4308 - Train Accuracy: 0.9737, Validation Accuracy: 0.9984, Loss: 0.0330\n",
      "Epoch   8 Batch 3600/4308 - Train Accuracy: 0.9934, Validation Accuracy: 0.9786, Loss: 0.0400\n",
      "Epoch   8 Batch 3900/4308 - Train Accuracy: 0.9704, Validation Accuracy: 0.9984, Loss: 0.0161\n",
      "Epoch   8 Batch 4200/4308 - Train Accuracy: 0.9766, Validation Accuracy: 1.0000, Loss: 0.0293\n",
      "Epoch   9 Batch  300/4308 - Train Accuracy: 0.9705, Validation Accuracy: 0.9984, Loss: 0.0498\n",
      "Epoch   9 Batch  600/4308 - Train Accuracy: 0.9797, Validation Accuracy: 0.9967, Loss: 0.0145\n",
      "Epoch   9 Batch  900/4308 - Train Accuracy: 0.9490, Validation Accuracy: 0.9984, Loss: 0.0247\n",
      "Epoch   9 Batch 1200/4308 - Train Accuracy: 0.9609, Validation Accuracy: 0.9984, Loss: 0.0617\n",
      "Epoch   9 Batch 1500/4308 - Train Accuracy: 0.9406, Validation Accuracy: 0.9967, Loss: 0.0397\n",
      "Epoch   9 Batch 1800/4308 - Train Accuracy: 0.9547, Validation Accuracy: 0.9984, Loss: 0.0183\n",
      "Epoch   9 Batch 2100/4308 - Train Accuracy: 0.9589, Validation Accuracy: 0.9984, Loss: 0.0180\n",
      "Epoch   9 Batch 2400/4308 - Train Accuracy: 0.9984, Validation Accuracy: 0.9984, Loss: 0.0100\n",
      "Epoch   9 Batch 2700/4308 - Train Accuracy: 0.9609, Validation Accuracy: 0.9934, Loss: 0.0403\n",
      "Epoch   9 Batch 3000/4308 - Train Accuracy: 0.9703, Validation Accuracy: 0.9967, Loss: 0.0361\n",
      "Epoch   9 Batch 3300/4308 - Train Accuracy: 0.9770, Validation Accuracy: 0.9984, Loss: 0.0245\n",
      "Epoch   9 Batch 3600/4308 - Train Accuracy: 1.0000, Validation Accuracy: 0.9786, Loss: 0.0142\n",
      "Epoch   9 Batch 3900/4308 - Train Accuracy: 0.9704, Validation Accuracy: 0.9984, Loss: 0.0272\n",
      "Epoch   9 Batch 4200/4308 - Train Accuracy: 0.9062, Validation Accuracy: 0.9770, Loss: 0.0287\n",
      "Epoch  10 Batch  300/4308 - Train Accuracy: 0.9479, Validation Accuracy: 0.9786, Loss: 0.0474\n",
      "Epoch  10 Batch  600/4308 - Train Accuracy: 0.9797, Validation Accuracy: 0.9770, Loss: 0.0194\n",
      "Epoch  10 Batch  900/4308 - Train Accuracy: 0.9408, Validation Accuracy: 0.9967, Loss: 0.0224\n",
      "Epoch  10 Batch 1200/4308 - Train Accuracy: 0.9828, Validation Accuracy: 0.9786, Loss: 0.0709\n",
      "Epoch  10 Batch 1500/4308 - Train Accuracy: 0.9187, Validation Accuracy: 0.9967, Loss: 0.0312\n",
      "Epoch  10 Batch 1800/4308 - Train Accuracy: 0.9547, Validation Accuracy: 0.9984, Loss: 0.0187\n",
      "Epoch  10 Batch 2100/4308 - Train Accuracy: 0.9819, Validation Accuracy: 0.9984, Loss: 0.0141\n",
      "Epoch  10 Batch 2400/4308 - Train Accuracy: 1.0000, Validation Accuracy: 0.9737, Loss: 0.0215\n",
      "Epoch  10 Batch 2700/4308 - Train Accuracy: 0.9844, Validation Accuracy: 0.9786, Loss: 0.0193\n",
      "Epoch  10 Batch 3000/4308 - Train Accuracy: 0.9906, Validation Accuracy: 0.9967, Loss: 0.0142\n",
      "Epoch  10 Batch 3300/4308 - Train Accuracy: 0.9556, Validation Accuracy: 0.9984, Loss: 0.0137\n",
      "Epoch  10 Batch 3600/4308 - Train Accuracy: 0.9967, Validation Accuracy: 0.9507, Loss: 0.0273\n",
      "Epoch  10 Batch 3900/4308 - Train Accuracy: 0.9704, Validation Accuracy: 0.9786, Loss: 0.0123\n",
      "Epoch  10 Batch 4200/4308 - Train Accuracy: 0.9281, Validation Accuracy: 0.9770, Loss: 0.0224\n",
      "Epoch  11 Batch  300/4308 - Train Accuracy: 0.9184, Validation Accuracy: 0.9984, Loss: 0.0302\n",
      "Epoch  11 Batch  600/4308 - Train Accuracy: 0.9812, Validation Accuracy: 0.9984, Loss: 0.0103\n",
      "Epoch  11 Batch  900/4308 - Train Accuracy: 0.9408, Validation Accuracy: 0.9770, Loss: 0.0238\n",
      "Epoch  11 Batch 1200/4308 - Train Accuracy: 0.9828, Validation Accuracy: 0.9770, Loss: 0.0565\n",
      "Epoch  11 Batch 1500/4308 - Train Accuracy: 0.9703, Validation Accuracy: 0.9984, Loss: 0.0294\n",
      "Epoch  11 Batch 1800/4308 - Train Accuracy: 0.9344, Validation Accuracy: 0.9984, Loss: 0.0104\n",
      "Epoch  11 Batch 2100/4308 - Train Accuracy: 0.9819, Validation Accuracy: 0.9984, Loss: 0.0273\n",
      "Epoch  11 Batch 2400/4308 - Train Accuracy: 0.9984, Validation Accuracy: 0.9984, Loss: 0.0102\n",
      "Epoch  11 Batch 2700/4308 - Train Accuracy: 0.9891, Validation Accuracy: 0.9984, Loss: 0.0141\n",
      "Epoch  11 Batch 3000/4308 - Train Accuracy: 0.9984, Validation Accuracy: 0.9984, Loss: 0.0171\n",
      "Epoch  11 Batch 3300/4308 - Train Accuracy: 0.9539, Validation Accuracy: 0.9984, Loss: 0.0183\n",
      "Epoch  11 Batch 3600/4308 - Train Accuracy: 0.9786, Validation Accuracy: 0.9984, Loss: 0.0236\n",
      "Epoch  11 Batch 3900/4308 - Train Accuracy: 1.0000, Validation Accuracy: 0.9984, Loss: 0.0119\n",
      "Epoch  11 Batch 4200/4308 - Train Accuracy: 0.9750, Validation Accuracy: 0.9786, Loss: 0.0147\n",
      "Epoch  12 Batch  300/4308 - Train Accuracy: 0.9688, Validation Accuracy: 0.9984, Loss: 0.0278\n",
      "Epoch  12 Batch  600/4308 - Train Accuracy: 0.9594, Validation Accuracy: 0.9967, Loss: 0.0101\n",
      "Epoch  12 Batch  900/4308 - Train Accuracy: 0.9408, Validation Accuracy: 0.9984, Loss: 0.0426\n",
      "Epoch  12 Batch 1200/4308 - Train Accuracy: 0.9766, Validation Accuracy: 0.9984, Loss: 0.0304\n",
      "Epoch  12 Batch 1500/4308 - Train Accuracy: 0.9328, Validation Accuracy: 0.9967, Loss: 0.0377\n",
      "Epoch  12 Batch 1800/4308 - Train Accuracy: 0.9766, Validation Accuracy: 0.9786, Loss: 0.0185\n",
      "Epoch  12 Batch 2100/4308 - Train Accuracy: 0.9803, Validation Accuracy: 0.9803, Loss: 0.0214\n",
      "Epoch  12 Batch 2400/4308 - Train Accuracy: 0.9984, Validation Accuracy: 0.9770, Loss: 0.0192\n",
      "Epoch  12 Batch 2700/4308 - Train Accuracy: 1.0000, Validation Accuracy: 0.9984, Loss: 0.0211\n",
      "Epoch  12 Batch 3000/4308 - Train Accuracy: 0.9984, Validation Accuracy: 0.9984, Loss: 0.0258\n",
      "Epoch  12 Batch 3300/4308 - Train Accuracy: 0.9753, Validation Accuracy: 0.9984, Loss: 0.0125\n",
      "Epoch  12 Batch 3600/4308 - Train Accuracy: 0.9720, Validation Accuracy: 0.9507, Loss: 0.0366\n",
      "Epoch  12 Batch 3900/4308 - Train Accuracy: 0.9704, Validation Accuracy: 0.9967, Loss: 0.0094\n",
      "Epoch  12 Batch 4200/4308 - Train Accuracy: 0.9516, Validation Accuracy: 0.9770, Loss: 0.0303\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, logits))\n",
    "\n",
    "# Split data to training and validation sets\n",
    "train_source = source_int_text[batch_size:]\n",
    "train_target = target_int_text[batch_size:]\n",
    "valid_source = source_int_text[:batch_size]\n",
    "valid_target = target_int_text[:batch_size]\n",
    "(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths ) = next(get_batches(valid_source,\n",
    "                                                                                                             valid_target,\n",
    "                                                                                                             batch_size,\n",
    "                                                                                                             source_vocab_to_int['<PAD>'],\n",
    "                                                                                                             target_vocab_to_int['<PAD>']))                                                                                                  \n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(\n",
    "                get_batches(train_source, train_target, batch_size,\n",
    "                            source_vocab_to_int['<PAD>'],\n",
    "                            target_vocab_to_int['<PAD>'])):\n",
    "\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                batch_train_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: source_batch,\n",
    "                     target_sequence_length: targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                batch_valid_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: valid_sources_batch,\n",
    "                     target_sequence_length: valid_targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "                valid_acc = get_accuracy(valid_targets_batch, batch_valid_logits)\n",
    "\n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n",
    "                      .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint               dev.index\r\n",
      "dev.data-00000-of-00001  dev.meta\r\n"
     ]
    }
   ],
   "source": [
    "ls checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/dev'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_params(params):\n",
    "    with open('params.p', 'wb') as out_file:\n",
    "        pickle.dump(params, out_file)\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    with open('params.p', mode='rb') as in_file:\n",
    "        return pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save parameters for checkpoint\n",
    "save_params(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import problem_unittests as tests\n",
    "\n",
    "_, (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = load_preprocess()\n",
    "load_path = load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    results = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in vocab_to_int:\n",
    "            results.append(vocab_to_int[word])\n",
    "        else:\n",
    "            results.append(vocab_to_int['<UNK'])\n",
    "    return results\n",
    "\n",
    "translate_sentence = 'he saw a old yellow truck .'\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dev\n",
      "Input\n",
      "  Word Ids:      [36, 176, 209, 53, 173, 229, 151]\n",
      "  English Words: ['he', 'saw', 'a', 'old', 'yellow', 'truck', '.']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [193, 87, 350, 233, 260, 245, 276, 232, 1]\n",
      "  French Words: il a vu un vieux camion jaune . <EOS>\n"
     ]
    }
   ],
   "source": [
    "### load graph and predict\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved graph\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "    \n",
    "    # Abstract tensors\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    \n",
    "    # Run computation graph\n",
    "    translate_logits = sess.run(logits, {input_data: [translate_sentence]*batch_size,\n",
    "                                         target_sequence_length: [len(translate_sentence)*2]*batch_size,\n",
    "                                         keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  English Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_logits]))\n",
    "print('  French Words: {}'.format(\" \".join([target_int_to_vocab[i] for i in translate_logits])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
